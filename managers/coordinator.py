"""
Coordinator - KullanÄ±cÄ±yla konuÅŸan ana etmen.
"""
from langchain_core.messages import HumanMessage
from config.settings import llm
from .task_manager import TaskManager


class Coordinator:
    """KullanÄ±cÄ±yla konuÅŸan ana etmen."""
    
    def __init__(self):
        self.manager = TaskManager()
    
    def generate_response(self, user_input, conversation_history=""):
        """KullanÄ±cÄ± girdisine yanÄ±t oluÅŸturur."""
        # AkÄ±ÅŸ baÅŸlangÄ±cÄ±
        flow_steps = [{
            "agent": "ğŸ§  COORDINATOR",
            "action": "Sorgu alÄ±ndÄ±",
            "detail": f"KullanÄ±cÄ± sorusu: '{user_input[:50]}...'"
        }]
        
        # 1. Task Manager'a sor (konuÅŸma geÃ§miÅŸiyle birlikte)
        manager_result = self.manager.decide_and_run(user_input, conversation_history)
        
        # Manager'dan gelen akÄ±ÅŸ adÄ±mlarÄ±nÄ± ekle
        if isinstance(manager_result, tuple) and len(manager_result) >= 3:
            worker_type, worker_data, manager_flow = manager_result
            flow_steps.extend(manager_flow)
        else:
            # Eski format desteÄŸi
            worker_type = "UNKNOWN"
            worker_data = manager_result
            manager_flow = []
        
        # Agent takip bilgisi
        agent_type = None
        agent_details = ""
        
        # 2. Sonucu iÅŸle
        if worker_type == "CHAT_MODE":
            agent_type = "ğŸ’¬ CHAT"
            agent_details = "Sohbet modu - Direkt LLM yanÄ±tÄ±"
            flow_steps.append({
                "agent": "ğŸ¤– LLM (Gemini)",
                "action": "Sohbet yanÄ±tÄ± oluÅŸturuluyor",
                "detail": "KonuÅŸma geÃ§miÅŸi kullanÄ±larak doÄŸal dil yanÄ±tÄ±"
            })
            # Sohbet modu
            final_prompt = f"""
            KonuÅŸma GeÃ§miÅŸi:
            {conversation_history}
            
            KullanÄ±cÄ±: {user_input}
            
            KonuÅŸma geÃ§miÅŸini dikkate alarak nazik bir ÅŸekilde cevap ver.
            """
        
        elif worker_type == "CALC":
            agent_type = "ğŸ§® CALCULATOR"
            agent_details = "Matematiksel hesaplama yapÄ±ldÄ±"
            # Hesaplama sonucu direkt dÃ¶ndÃ¼r
            return (f"ğŸ“Š Hesaplama Sonucu: {worker_data}", agent_type, agent_details, flow_steps)
        
        elif worker_type == "SEARCH":
            agent_type = "ğŸ” WEB SEARCH"
            agent_details = "Tavily Ã¼zerinden web aramasÄ± yapÄ±ldÄ±"
            flow_steps.append({
                "agent": "ğŸ¤– LLM (Gemini)",
                "action": "Web sonuÃ§larÄ±nÄ± Ã¶zetliyor",
                "detail": "Ham veri Ã¶zetleniyor"
            })
            # Web arama sonucunu LLM ile Ã¶zetle
            final_prompt = f"""
            KullanÄ±cÄ± sorusu: {user_input}
            Web aramasÄ± sonuÃ§larÄ±:
            {worker_data}
            
            GÃ¶revin: Bu web arama sonuÃ§larÄ±nÄ± kullanarak kullanÄ±cÄ±ya Ã¶zetlenmiÅŸ, TÃ¼rkÃ§e bir cevap ver.
            Ã–NEMLÄ°: Kaynaklara atÄ±fta bulun.
            """
        
        elif worker_type == "WIKI":
            agent_type = "ğŸ“š WIKIPEDIA"
            agent_details = "Wikipedia TÃ¼rkÃ§e'den bilgi alÄ±ndÄ±"
            flow_steps.append({
                "agent": "ğŸ¤– LLM (Gemini)",
                "action": "Wikipedia verisini iÅŸliyor",
                "detail": "Ham veri kullanÄ±cÄ± dostu yanÄ±ta dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor"
            })
            final_prompt = f"""
            KonuÅŸma GeÃ§miÅŸi:
            {conversation_history}
            
            KullanÄ±cÄ± sorusu: {user_input}
            Wikipedia'dan gelen ham veri: {worker_data}
            
            GÃ¶revin: Bu ham veriyi kullanarak kullanÄ±cÄ±ya nazik, kibar ve TÃ¼rkÃ§e bir cevap ver.
            Ã–NEMLÄ°: KonuÅŸma geÃ§miÅŸini dikkate al, tutarlÄ± ol.
            Ã–NEMLÄ° KURAL: CevabÄ±n minimum 5 cÃ¼mle olsun. Ã‡ok da uzatma.
            Ã–NEMLÄ° KURAL 2: Ne zaman, nerede gibi sorular gelirse konu baÅŸlÄ±ÄŸÄ±nÄ± anlatma, soruyu cevapla.
            """
        else:
            # Fallback
            agent_type = "â“ UNKNOWN"
            agent_details = "Bilinmeyen iÅŸlem"
            final_prompt = f"KullanÄ±cÄ±: {user_input}"

        try:
            response = llm.invoke([HumanMessage(content=final_prompt)])
            return (response.content, agent_type, agent_details, flow_steps)
        except Exception as e:
            return (f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}", "âŒ HATA", str(e), flow_steps)
